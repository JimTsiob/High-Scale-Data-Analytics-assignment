{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T12:43:33.261978Z",
     "iopub.status.busy": "2024-01-22T12:43:33.261557Z",
     "iopub.status.idle": "2024-01-22T12:44:08.029209Z",
     "shell.execute_reply": "2024-01-22T12:44:08.027361Z",
     "shell.execute_reply.started": "2024-01-22T12:43:33.261945Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandarallel\n",
    "!pip install datasketch\n",
    "print(\"INSTALLATIONS COMPLETE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T12:44:08.034129Z",
     "iopub.status.busy": "2024-01-22T12:44:08.033594Z",
     "iopub.status.idle": "2024-01-22T12:44:12.586020Z",
     "shell.execute_reply": "2024-01-22T12:44:12.584972Z",
     "shell.execute_reply.started": "2024-01-22T12:44:08.034093Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score,roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pandarallel import pandarallel\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_validate, KFold, cross_val_score, StratifiedKFold , cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import NearestNeighbors, VALID_METRICS_SPARSE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import normalize, binarize\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Download and unzip wordnet\n",
    "try:\n",
    "    nltk.data.find('wordnet.zip')\n",
    "except:\n",
    "    nltk.download('wordnet', download_dir='/kaggle/working/')\n",
    "    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n",
    "    subprocess.run(command.split())\n",
    "    nltk.data.path.append('/kaggle/working/')\n",
    "    \n",
    "\n",
    "print('Imports done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T12:44:12.588511Z",
     "iopub.status.busy": "2024-01-22T12:44:12.587229Z",
     "iopub.status.idle": "2024-01-22T12:44:24.387680Z",
     "shell.execute_reply": "2024-01-22T12:44:24.386479Z",
     "shell.execute_reply.started": "2024-01-22T12:44:12.588471Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/bigdata2023classification/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/bigdata2023classification/test_without_labels.csv')\n",
    "\n",
    "train_df['Label_id'] = train_df['Label'].factorize()[0] # create specific ID for each label. Helps later on with wordclouds and XGBoost.\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T12:44:24.390616Z",
     "iopub.status.busy": "2024-01-22T12:44:24.390200Z",
     "iopub.status.idle": "2024-01-22T12:44:24.705246Z",
     "shell.execute_reply": "2024-01-22T12:44:24.703913Z",
     "shell.execute_reply.started": "2024-01-22T12:44:24.390583Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize our data (specifically the Label column)\n",
    "# Data Distribution\n",
    "\n",
    "train_df.groupby('Label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T12:44:24.706988Z",
     "iopub.status.busy": "2024-01-22T12:44:24.706645Z",
     "iopub.status.idle": "2024-01-22T12:44:25.090442Z",
     "shell.execute_reply": "2024-01-22T12:44:25.089222Z",
     "shell.execute_reply.started": "2024-01-22T12:44:24.706960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Countplot for column Label, there seem to be more entertainment articles.\n",
    "sns.countplot(x='Label',data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which ID corresponds to which label\n",
    "label = train_df[['Label', 'Label_id']].drop_duplicates().sort_values('Label_id')\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shapes\n",
    "print('train_df size: ', train_df.shape)\n",
    "print('test_df size: ', test_df.shape)\n",
    "# 159707 full size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T09:17:02.853166Z",
     "iopub.status.busy": "2024-01-18T09:17:02.852746Z",
     "iopub.status.idle": "2024-01-18T09:22:33.827350Z",
     "shell.execute_reply": "2024-01-18T09:22:33.825642Z",
     "shell.execute_reply.started": "2024-01-18T09:17:02.853132Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T13:14:45.067071Z",
     "iopub.status.busy": "2024-01-22T13:14:45.065658Z",
     "iopub.status.idle": "2024-01-22T13:21:31.222827Z",
     "shell.execute_reply": "2024-01-22T13:21:31.221502Z",
     "shell.execute_reply.started": "2024-01-22T13:14:45.067009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text preprocessing for Content column\n",
    "# Lower all text\n",
    "\n",
    "train_df['Content'] = train_df['Content'].str.lower()\n",
    "test_df['Content'] = test_df['Content'].str.lower()\n",
    "\n",
    "# Initialize pandarallel\n",
    "# I used pandarallel because it applies the functions much faster than a normal pandas apply.\n",
    "pandarallel.initialize(nb_workers=8,progress_bar=True)\n",
    "\n",
    "# Remove all special characters\n",
    "def remove_special_chars(text):\n",
    "    return ''.join(x if x.isalnum() else ' ' for x in text)\n",
    "\n",
    "train_df['Content'] = train_df['Content'].parallel_apply(remove_special_chars)\n",
    "test_df['Content'] = test_df['Content'].parallel_apply(remove_special_chars)\n",
    "\n",
    "# get stopwords.\n",
    "stop = set(stopwords.words('english'))\n",
    "extra_stopwords = {'well', 'said', 'say', 'one', 'even'}\n",
    "stop.update(extra_stopwords)\n",
    "\n",
    "# Remove stop_words\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    return [x for x in words if x not in stop]\n",
    "\n",
    "train_df['Content'] = train_df['Content'].parallel_apply(remove_stopwords)\n",
    "test_df['Content'] = test_df['Content'].parallel_apply(remove_stopwords)\n",
    "\n",
    "# Lemmatization\n",
    "def lemmatize_word(text):\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    return \" \".join([wordnet.lemmatize(word) for word in text])\n",
    "\n",
    "train_df['Content'] = train_df['Content'].parallel_apply(lemmatize_word)\n",
    "test_df['Content'] = test_df['Content'].parallel_apply(lemmatize_word)\n",
    "\n",
    "\n",
    "\n",
    "print('Example of preprocessing train: ')\n",
    "print(train_df['Content'][0])\n",
    "print(\"\\n\")\n",
    "print('Example of preprocessing test: ')\n",
    "print(test_df['Content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T13:21:31.227777Z",
     "iopub.status.busy": "2024-01-22T13:21:31.226718Z",
     "iopub.status.idle": "2024-01-22T13:27:41.560086Z",
     "shell.execute_reply": "2024-01-22T13:27:41.558503Z",
     "shell.execute_reply.started": "2024-01-22T13:21:31.227711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word cloud creation\n",
    "\n",
    "# get each label's articles to create word cloud for each label\n",
    "entertainment = train_df[train_df['Label_id'] == 0]\n",
    "entertainment = entertainment['Content']\n",
    "\n",
    "technology = train_df[train_df['Label_id'] == 1]\n",
    "technology = technology['Content']\n",
    "\n",
    "business = train_df[train_df['Label_id'] == 2]\n",
    "business = business['Content']\n",
    "\n",
    "health = train_df[train_df['Label_id'] == 3]\n",
    "health = health['Content']\n",
    "\n",
    "def wordcloud_draw(dataset, color = 'white'):\n",
    "    words = ' '.join(dataset)\n",
    "    cleaned_word = ' '.join([word for word in words.split()\n",
    "    if (word != 'news' and word != 'text')])\n",
    "    wordcloud = WordCloud(stopwords = stop,\n",
    "    background_color = color,\n",
    "    width = 2500, height = 2500).generate(cleaned_word)\n",
    "    plt.figure(1, figsize = (10,7))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "print('Entertainment wordcloud: ')\n",
    "wordcloud_draw(entertainment)\n",
    "\n",
    "print('Technology wordcloud: ')\n",
    "wordcloud_draw(technology)\n",
    "\n",
    "print('Business wordcloud: ')\n",
    "wordcloud_draw(business)\n",
    "\n",
    "print('Health wordcloud: ')\n",
    "wordcloud_draw(health)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-29T15:36:42.266594Z",
     "iopub.status.idle": "2023-12-29T15:36:42.267442Z",
     "shell.execute_reply": "2023-12-29T15:36:42.267181Z",
     "shell.execute_reply.started": "2023-12-29T15:36:42.267155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count vectorizer will represent the BOW model.\n",
    "\n",
    "X_train = train_df['Content']\n",
    "X_test = test_df['Content']\n",
    "y_train = train_df['Label']\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = count_vectorizer.fit_transform(train_df['Content'])\n",
    "X_test = count_vectorizer.transform(test_df['Content'])\n",
    "\n",
    "print('Preprocessing complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM training and evaluation (with BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T11:31:02.075977Z",
     "iopub.status.busy": "2023-12-23T11:31:02.073961Z",
     "iopub.status.idle": "2023-12-23T11:35:28.057928Z",
     "shell.execute_reply": "2023-12-23T11:35:28.056310Z",
     "shell.execute_reply.started": "2023-12-23T11:31:02.075874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "# using LinearSVC because it's faster for large datasets , that can be separated linearly \n",
    "# and supports One-vs-Rest technique (Great for multi-class labels like our case). \n",
    "\n",
    "svm_model = LinearSVC(random_state = 42, max_iter=1000)\n",
    "\n",
    "# Perform 5-fold cross-validation and get predictions for each fold\n",
    "y_pred = cross_val_predict(svm_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Print classification report for each category\n",
    "print(\"====================== SVM Classification Report (BOW) ======================\")\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest training and evaluation (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T11:38:00.804224Z",
     "iopub.status.busy": "2023-12-23T11:38:00.803076Z",
     "iopub.status.idle": "2023-12-23T11:45:52.263559Z",
     "shell.execute_reply": "2023-12-23T11:45:52.261538Z",
     "shell.execute_reply.started": "2023-12-23T11:38:00.804179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a random forest classifier with 20 Decision trees. Took a small number of trees here because it's really slow with BOW.\n",
    "rf_model = RandomForestClassifier(n_estimators=20,n_jobs=-1)\n",
    "\n",
    "# Perform 5-fold cross-validation and get predictions for each fold\n",
    "y_pred = cross_val_predict(rf_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Print classification report for each category\n",
    "print(\"====================== Random Forest Classification Report (BOW) ======================\")\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T12:39:15.236295Z",
     "iopub.status.busy": "2023-12-23T12:39:15.234952Z",
     "iopub.status.idle": "2023-12-23T12:40:18.814298Z",
     "shell.execute_reply": "2023-12-23T12:40:18.813250Z",
     "shell.execute_reply.started": "2023-12-23T12:39:15.236233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform SVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_train_reduced = svd.fit_transform(X_train)\n",
    "X_test_reduced = svd.transform(X_test)\n",
    "print(\"SVD complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Training and evaluation (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T12:40:18.817653Z",
     "iopub.status.busy": "2023-12-23T12:40:18.816842Z",
     "iopub.status.idle": "2023-12-23T13:01:37.618960Z",
     "shell.execute_reply": "2023-12-23T13:01:37.617630Z",
     "shell.execute_reply.started": "2023-12-23T12:40:18.817607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "# using LinearSVC because it's faster for large datasets , that can be separated linearly \n",
    "# and supports One-vs-Rest technique (Great for multi-class labels like our case). \n",
    "\n",
    "svm_model = LinearSVC(random_state = 42, max_iter=1000)\n",
    "\n",
    "# Perform 5-fold cross-validation and get predictions for each fold\n",
    "y_pred = cross_val_predict(svm_model, X_train_reduced, y_train, cv=5)\n",
    "\n",
    "# Print classification report for each category\n",
    "print(\"====================== SVM Classification Report (SVD) ======================\")\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest training and evaluation (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T13:13:03.269656Z",
     "iopub.status.busy": "2023-12-23T13:13:03.269185Z",
     "iopub.status.idle": "2023-12-23T13:18:03.109457Z",
     "shell.execute_reply": "2023-12-23T13:18:03.108173Z",
     "shell.execute_reply.started": "2023-12-23T13:13:03.269623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a random forest classifier with 100 Decision trees (SVD cross validation is faster than BOW for Random Forest).\n",
    "rf_model = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "# Perform 5-fold cross-validation and get predictions for each fold\n",
    "y_pred = cross_val_predict(rf_model, X_train_reduced, y_train, cv=5)\n",
    "\n",
    "# Print classification report for each category\n",
    "print(\"====================== Random Forest Classification Report (SVD) ======================\")\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beat the benchmark algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T09:30:50.277311Z",
     "iopub.status.busy": "2024-01-18T09:30:50.276920Z",
     "iopub.status.idle": "2024-01-18T09:31:34.027308Z",
     "shell.execute_reply": "2024-01-18T09:31:34.025674Z",
     "shell.execute_reply.started": "2024-01-18T09:30:50.277277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Title added as feature with content (combined), increases accuracy a little bit (0.3% increase).\n",
    "train_df['Title'] = train_df['Title'].str.lower()\n",
    "test_df['Title'] = test_df['Title'].str.lower()\n",
    "\n",
    "pandarallel.initialize(nb_workers=8,progress_bar=True)\n",
    "\n",
    "train_df['Title'] = train_df['Title'].parallel_apply(remove_special_chars)\n",
    "test_df['Title'] = test_df['Title'].parallel_apply(remove_special_chars)\n",
    "\n",
    "train_df['Title'] = train_df['Title'].parallel_apply(remove_stopwords)\n",
    "test_df['Title'] = test_df['Title'].parallel_apply(remove_stopwords)\n",
    "\n",
    "train_df['Title'] = train_df['Title'].parallel_apply(lemmatize_word)\n",
    "test_df['Title'] = test_df['Title'].parallel_apply(lemmatize_word)\n",
    "\n",
    "train_df['Combined'] = train_df['Title'] + ' ' + train_df['Content']\n",
    "test_df['Combined'] = test_df['Title'] + ' ' + test_df['Content']\n",
    "\n",
    "print('Example of preprocessing train: ')\n",
    "print(train_df['Combined'][0])\n",
    "print(\"\\n\")\n",
    "print('Example of preprocessing test: ')\n",
    "print(test_df['Combined'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T09:31:34.033220Z",
     "iopub.status.busy": "2024-01-18T09:31:34.032044Z",
     "iopub.status.idle": "2024-01-18T09:32:19.485974Z",
     "shell.execute_reply": "2024-01-18T09:32:19.484375Z",
     "shell.execute_reply.started": "2024-01-18T09:31:34.033175Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_df['Combined']\n",
    "X_test = test_df['Combined']\n",
    "y_train = train_df['Label']\n",
    "\n",
    "# Using hashing vectorizer as it's a better form of the classic BOW count vectorizer,\n",
    "# giving me the best possible results.\n",
    "\n",
    "hashing_vectorizer = HashingVectorizer()\n",
    "X_train = hashing_vectorizer.fit_transform(train_df['Combined'])\n",
    "X_test = hashing_vectorizer.transform(test_df['Combined'])\n",
    "\n",
    "print('Preprocessing complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T13:24:01.944209Z",
     "iopub.status.busy": "2023-12-23T13:24:01.943706Z",
     "iopub.status.idle": "2023-12-23T13:26:32.544590Z",
     "shell.execute_reply": "2023-12-23T13:26:32.543403Z",
     "shell.execute_reply.started": "2023-12-23T13:24:01.944171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression model (BOW) , testing this model but it gave me worse results than LinearSVC with hashing vectorizer.\n",
    "# Using sag solver since it finishes the fastest out of all solvers (along with saga, 2 minutes)\n",
    "\n",
    "lr_model = LogisticRegression(tol=1e-4, C=1.0, n_jobs=-1, solver='sag',random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation and get predictions for each fold\n",
    "y_pred = cross_val_predict(lr_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Print classification report for each category\n",
    "print(\"====================== Logistic Regression Classification Report ======================\")\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T14:05:17.299449Z",
     "iopub.status.busy": "2023-12-23T14:05:17.298612Z",
     "iopub.status.idle": "2023-12-23T14:13:29.286636Z",
     "shell.execute_reply": "2023-12-23T14:13:29.285276Z",
     "shell.execute_reply.started": "2023-12-23T14:05:17.299403Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=20, max_depth=3, random_state=42)\n",
    "\n",
    "y_label_ids = train_df['Label_id']\n",
    "\n",
    "# Perform 5-fold cross-validation and get predictions for each fold\n",
    "y_pred = cross_val_predict(xgb_model, X_train, y_label_ids, cv=5)\n",
    "\n",
    "# Print classification report for each category\n",
    "print(\"====================== XGBoost Classification Report ======================\")\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_label_ids, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:48:31.714079Z",
     "iopub.status.busy": "2023-12-23T16:48:31.713658Z",
     "iopub.status.idle": "2023-12-23T16:49:16.260366Z",
     "shell.execute_reply": "2023-12-23T16:49:16.259170Z",
     "shell.execute_reply.started": "2023-12-23T16:48:31.714046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "# using LinearSVC because it's faster for large datasets , that can be separated linearly \n",
    "# and supports One-vs-Rest technique (Great for multi-class labels like our case). \n",
    "\n",
    "# Best model with 97% accuracy\n",
    "\n",
    "svm_model = LinearSVC(random_state=42, max_iter=1000)\n",
    "\n",
    "# Perform 5-fold cross-validation and get predictions for each fold\n",
    "y_pred = cross_val_predict(svm_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Print classification report for each category\n",
    "print(\"====================== SVM Classification Report (Best model) ======================\")\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:49:16.262642Z",
     "iopub.status.busy": "2023-12-23T16:49:16.262213Z",
     "iopub.status.idle": "2023-12-23T16:49:25.278627Z",
     "shell.execute_reply": "2023-12-23T16:49:25.277542Z",
     "shell.execute_reply.started": "2023-12-23T16:49:16.262607Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:49:25.280617Z",
     "iopub.status.busy": "2023-12-23T16:49:25.280149Z",
     "iopub.status.idle": "2023-12-23T16:49:25.979740Z",
     "shell.execute_reply": "2023-12-23T16:49:25.978435Z",
     "shell.execute_reply.started": "2023-12-23T16:49:25.280574Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('testSet_categories.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    writer.writerow([\"Id\",\"Predicted\"])\n",
    "    for i in range(0,47912):\n",
    "        writer.writerow([test_df['Id'][i],y_pred_test[i]])  \n",
    "    \n",
    "    \n",
    "print(\"CSV file writing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute force k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T09:32:19.489764Z",
     "iopub.status.busy": "2024-01-18T09:32:19.489211Z",
     "iopub.status.idle": "2024-01-18T09:50:22.288917Z",
     "shell.execute_reply": "2024-01-18T09:50:22.286562Z",
     "shell.execute_reply.started": "2024-01-18T09:32:19.489715Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "# turn hash-vectorized sparse matrices to SVD arrays in order to get faster computation.\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_train_reduced = svd.fit_transform(X_train)\n",
    "X_test_reduced = svd.transform(X_test)\n",
    "\n",
    "# Make SVD arrays to binary format for proper jaccard computation.\n",
    "X_train_binary = binarize(X_train_reduced)\n",
    "X_test_binary = binarize(X_test_reduced)\n",
    "\n",
    "print(\"x_train_binary shape: \", X_train_binary.shape)\n",
    "\n",
    "print('svd done.')\n",
    "\n",
    "start_time = time.time()\n",
    "nbrs = NearestNeighbors(n_neighbors=15, algorithm='brute', metric='jaccard', n_jobs=-1).fit(X_train_binary)\n",
    "build_time = time.time() - start_time\n",
    "print(f\"Build time: {build_time} seconds\")\n",
    "\n",
    "print('nbrs done.')\n",
    "\n",
    "# Suppress DataConversionWarning for this block , to save some room\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "    start_time = time.time()\n",
    "    distances, indices = nbrs.kneighbors(X_test_binary)\n",
    "    query_time = time.time() - start_time\n",
    "    print(f\"Query time: {query_time} seconds\")\n",
    "\n",
    "\n",
    "print('k-nn done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T09:50:40.739016Z",
     "iopub.status.busy": "2024-01-18T09:50:40.737552Z",
     "iopub.status.idle": "2024-01-18T09:50:40.749702Z",
     "shell.execute_reply": "2024-01-18T09:50:40.747651Z",
     "shell.execute_reply.started": "2024-01-18T09:50:40.738964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking NearestNeighbors validity (if what is found is correct)\n",
    "# Both articles seem to be correct, since they're business related.\n",
    "print(\"Source Example:\")\n",
    "print(test_df.iloc[1]['Combined'])\n",
    "\n",
    "print('\\n')\n",
    "print(\"Neighbor:\")\n",
    "print(train_df.iloc[indices[1][0]]['Combined'])\n",
    "\n",
    "print('\\n')\n",
    "print(indices[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-hash LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T09:50:48.183915Z",
     "iopub.status.busy": "2024-01-18T09:50:48.183351Z",
     "iopub.status.idle": "2024-01-18T09:54:27.665821Z",
     "shell.execute_reply": "2024-01-18T09:54:27.664019Z",
     "shell.execute_reply.started": "2024-01-18T09:50:48.183871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize and create sets of tokens\n",
    "\n",
    "pandarallel.initialize(nb_workers=8,progress_bar=True)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return set(word_tokenize(text))\n",
    "\n",
    "# Tokenize and create sets of tokens for test_df and train_df\n",
    "train_df['Tokenized'] = train_df['Combined'].parallel_apply(lambda x: tokenize_text(x))\n",
    "test_df['Tokenized'] = test_df['Combined'].parallel_apply(lambda x: tokenize_text(x))\n",
    "\n",
    "# Now train_df['Tokenized'] contains sets of tokens for each article\n",
    "print(train_df['Tokenized'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T09:54:27.669980Z",
     "iopub.status.busy": "2024-01-18T09:54:27.668848Z",
     "iopub.status.idle": "2024-01-18T10:04:27.775337Z",
     "shell.execute_reply": "2024-01-18T10:04:27.773631Z",
     "shell.execute_reply.started": "2024-01-18T09:54:27.669931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Min Hash LSH\n",
    "\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "minhash_objects = []\n",
    "\n",
    "def create_minhash(tokens):\n",
    "    minhash = MinHash(num_perm=16)\n",
    "    for token in tokens:\n",
    "        minhash.update(token.encode('utf8'))\n",
    "    return minhash\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "minhash_objects = list(map(create_minhash, train_df['Tokenized']))\n",
    "\n",
    "# Create MinHashLSH Index\n",
    "# lsh = MinHashLSH(threshold=0.8, num_perm=16)\n",
    "\n",
    "# for i, minhash in enumerate(minhash_objects):\n",
    "#     lsh.insert(i, minhash)\n",
    "\n",
    "\n",
    "test_minhash_objects = []\n",
    "# Create MinHash objects for test_df\n",
    "test_minhash_objects = list(map(create_minhash, test_df['Tokenized']))\n",
    "\n",
    "\n",
    "# Query MinHashLSH for candidates in train_df\n",
    "\n",
    "\n",
    "# Create MinHashLSH Index\n",
    "lsh = MinHashLSH(threshold=0.8, num_perm=16)\n",
    "\n",
    "for i, minhash in enumerate(minhash_objects):\n",
    "    lsh.insert(i, minhash)\n",
    "    \n",
    "build_time = time.time() - start_time\n",
    "print(f\"Build time (lsh with 16 permutations, threshold >= 0.8): {build_time} seconds\")\n",
    "# test_candidates = []\n",
    "# for i, minhash in enumerate(test_minhash_objects):\n",
    "#     result = lsh.query(minhash)\n",
    "#     test_candidates.append(result)\n",
    "start_time = time.time()\n",
    "test_candidates = [lsh.query(minhash) for minhash in test_minhash_objects]\n",
    "\n",
    "query_time = time.time() - start_time\n",
    "print(f\"Query time (lsh with 16 permutations, threshold >= 0.8): {query_time} seconds\")\n",
    "\n",
    "# num_neighbors = 15\n",
    "\n",
    "# neighbors = []\n",
    "# for i, minhash in enumerate(minhash_objects):\n",
    "#     result = lsh.query(minhash)\n",
    "# #     print(f\"Neighbors for document {i + 1} ({df['document_id'][i]}): {result}\")\n",
    "#     neighbors.append(result)\n",
    "\n",
    "print('min hash done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T10:10:36.780816Z",
     "iopub.status.busy": "2024-01-18T10:10:36.780165Z",
     "iopub.status.idle": "2024-01-18T10:10:36.946952Z",
     "shell.execute_reply": "2024-01-18T10:10:36.945610Z",
     "shell.execute_reply.started": "2024-01-18T10:10:36.780768Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_candidates_flat = test_candidates.flatten(), jic -> / 1000\n",
    "test_candidates_flat = [item for sublist in test_candidates for item in sublist]\n",
    "print(len(test_candidates_flat))\n",
    "indices_flat = indices.flatten()\n",
    "print(\"Fraction of true k-most similar docs found by LSH (16 perms): \", len(set(test_candidates_flat).intersection(indices_flat)) / 15) # find fraction for K=15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T10:10:41.494905Z",
     "iopub.status.busy": "2024-01-18T10:10:41.494433Z",
     "iopub.status.idle": "2024-01-18T10:21:27.563423Z",
     "shell.execute_reply": "2024-01-18T10:21:27.561833Z",
     "shell.execute_reply.started": "2024-01-18T10:10:41.494858Z"
    }
   },
   "outputs": [],
   "source": [
    "# 32 permutations minhash LSH\n",
    "minhash_objects_32 = []\n",
    "\n",
    "def create_minhash(tokens):\n",
    "    minhash = MinHash(num_perm=32)\n",
    "    for token in tokens:\n",
    "        minhash.update(token.encode('utf8'))\n",
    "    return minhash\n",
    "\n",
    "start_time = time.time()\n",
    "minhash_objects_32 = list(map(create_minhash, train_df['Tokenized']))\n",
    "\n",
    "# Create MinHashLSH Index\n",
    "lsh2 = MinHashLSH(threshold=0.8, num_perm=32)\n",
    "\n",
    "for i, minhash in enumerate(minhash_objects_32):\n",
    "    lsh2.insert(i, minhash)\n",
    "\n",
    "build_time = time.time() - start_time\n",
    "print(f\"Build time (lsh with 32 permutations, threshold >= 0.8): {build_time} seconds\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Create MinHash objects for test_df\n",
    "test_minhash_objects_32 = list(map(create_minhash, test_df['Tokenized']))\n",
    "\n",
    "# Query MinHashLSH for candidates in train_df\n",
    "test_candidates_32 = [lsh2.query(minhash) for minhash in test_minhash_objects_32]\n",
    "\n",
    "dups_dict_32 = {}\n",
    "\n",
    "for i,minhash in enumerate(test_candidates_32):\n",
    "    dups_dict_32[i] = minhash\n",
    "\n",
    "query_time = time.time() - start_time\n",
    "print(f\"Query time (lsh with 32 permutations, threshold >= 0.8): {query_time} seconds\")\n",
    "\n",
    "max_length = len(max(test_candidates_32, key=len))\n",
    "print(\"length of list of neighbors with most neighbors (32 permutations minhash LSH):\", max_length)\n",
    "\n",
    "sum_of_lengths = sum(len(sublist) for sublist in test_candidates_32)\n",
    "print(\"Sum of neighbors (32 permutations): \", sum_of_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T10:21:27.566331Z",
     "iopub.status.busy": "2024-01-18T10:21:27.565894Z",
     "iopub.status.idle": "2024-01-18T10:21:27.740245Z",
     "shell.execute_reply": "2024-01-18T10:21:27.738632Z",
     "shell.execute_reply.started": "2024-01-18T10:21:27.566297Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_candidates_flat = test_candidates.flatten(), , jic -> / 1000\n",
    "test_candidates_flat_32 = [item for sublist in test_candidates_32 for item in sublist]\n",
    "print(len(test_candidates_flat_32))\n",
    "indices_flat = indices.flatten()\n",
    "print(\"Fraction of true k-most similar docs found by LSH (32 perms): \", len(set(test_candidates_flat_32).intersection(indices_flat)) / 15) # find fraction for K=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T10:42:06.265537Z",
     "iopub.status.busy": "2024-01-11T10:42:06.265046Z",
     "iopub.status.idle": "2024-01-11T10:47:59.573707Z",
     "shell.execute_reply": "2024-01-11T10:47:59.572727Z",
     "shell.execute_reply.started": "2024-01-11T10:42:06.265509Z"
    }
   },
   "outputs": [],
   "source": [
    "# 64 permutations minhash LSH\n",
    "minhash_objects_64 = []\n",
    "\n",
    "def create_minhash(tokens):\n",
    "    minhash = MinHash(num_perm=64)\n",
    "    for token in tokens:\n",
    "        minhash.update(token.encode('utf8'))\n",
    "    return minhash\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "minhash_objects_64 = list(map(create_minhash, train_df['Tokenized']))\n",
    "\n",
    "# Create MinHashLSH Index\n",
    "lsh3 = MinHashLSH(threshold=0.8, num_perm=64)\n",
    "\n",
    "for i, minhash in enumerate(minhash_objects_64):\n",
    "    lsh3.insert(i, minhash)\n",
    "\n",
    "build_time = time.time() - start_time\n",
    "print(f\"Build time (lsh with 64 permutations, threshold >= 0.8): {build_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "# Create MinHash objects for test_df\n",
    "test_minhash_objects_64 = list(map(create_minhash, test_df['Tokenized']))\n",
    "\n",
    "# Query MinHashLSH for candidates in train_df\n",
    "test_candidates_64 = [lsh3.query(minhash) for minhash in test_minhash_objects_64]\n",
    "\n",
    "query_time = time.time() - start_time\n",
    "print(f\"Query time (lsh with 64 permutations, threshold >= 0.8): {query_time} seconds\")\n",
    "\n",
    "\n",
    "max_length = len(max(test_candidates_64, key=len))\n",
    "print(\"length of list of neighbors with most neighbors (64 permutations minhash LSH):\", max_length)\n",
    "# print(test_candidates)\n",
    "sum_of_lengths = sum(len(sublist) for sublist in test_candidates_64)\n",
    "print(\"Sum of neighbors (64 permutations): \", sum_of_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T10:50:20.410265Z",
     "iopub.status.busy": "2024-01-11T10:50:20.409525Z",
     "iopub.status.idle": "2024-01-11T10:50:20.474355Z",
     "shell.execute_reply": "2024-01-11T10:50:20.473024Z",
     "shell.execute_reply.started": "2024-01-11T10:50:20.410212Z"
    }
   },
   "outputs": [],
   "source": [
    "# jic -> / 1000\n",
    "test_candidates_flat_64 = [item for sublist in test_candidates_64 for item in sublist]\n",
    "print(len(test_candidates_flat_64))\n",
    "indices_flat = indices.flatten()\n",
    "print(\"Fraction of true k-most similar docs found by LSH (64 perms): \", len(set(test_candidates_flat_64).intersection(indices_flat)) / 15) # find fraction for K=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T11:09:06.585220Z",
     "iopub.status.busy": "2024-01-11T11:09:06.584144Z",
     "iopub.status.idle": "2024-01-11T11:14:13.728894Z",
     "shell.execute_reply": "2024-01-11T11:14:13.727651Z",
     "shell.execute_reply.started": "2024-01-11T11:09:06.585180Z"
    }
   },
   "outputs": [],
   "source": [
    "# 16 permutations minhash LSH with >= 0.5 threshold\n",
    "minhash_objects = []\n",
    "\n",
    "def create_minhash(tokens):\n",
    "    minhash = MinHash(num_perm=16)\n",
    "    for token in tokens:\n",
    "        minhash.update(token.encode('utf8'))\n",
    "    return minhash\n",
    "\n",
    "start_time = time.time()\n",
    "minhash_objects = list(map(create_minhash, train_df['Tokenized']))\n",
    "\n",
    "# Create MinHashLSH Index\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=16)\n",
    "\n",
    "for i, minhash in enumerate(minhash_objects):\n",
    "    lsh.insert(i, minhash)\n",
    "\n",
    "build_time = time.time() - start_time\n",
    "print(f\"Build time (lsh with 16 permutations, threshold >= 0.5): {build_time} seconds\")\n",
    "\n",
    "# Create MinHash objects for test_df\n",
    "start_time = time.time()\n",
    "test_minhash_objects = list(map(create_minhash, test_df['Tokenized']))\n",
    "\n",
    "# Query MinHashLSH for candidates in train_df\n",
    "    \n",
    "test_candidates = [lsh.query(minhash) for minhash in test_minhash_objects]    \n",
    "\n",
    "query_time = time.time() - start_time\n",
    "print(f\"Query time (lsh with 16 permutations, threshold >= 0.5): {query_time} seconds\")\n",
    "\n",
    "# print(test_candidates)\n",
    "print('min hash done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T11:16:30.346649Z",
     "iopub.status.busy": "2024-01-11T11:16:30.345530Z",
     "iopub.status.idle": "2024-01-11T11:16:30.641014Z",
     "shell.execute_reply": "2024-01-11T11:16:30.640107Z",
     "shell.execute_reply.started": "2024-01-11T11:16:30.346607Z"
    }
   },
   "outputs": [],
   "source": [
    "# , jic -> / 100\n",
    "test_candidates_flat = [item for sublist in test_candidates for item in sublist]\n",
    "print(len(test_candidates_flat))\n",
    "indices_flat = indices.flatten()\n",
    "print(\"Fraction of true k-most similar docs found by LSH (16 perms, >= 0.5 threshold): \", len(set(test_candidates_flat).intersection(indices_flat)) / 15) # find fraction for K=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T11:17:40.082732Z",
     "iopub.status.busy": "2024-01-11T11:17:40.082097Z",
     "iopub.status.idle": "2024-01-11T11:23:04.519855Z",
     "shell.execute_reply": "2024-01-11T11:23:04.518689Z",
     "shell.execute_reply.started": "2024-01-11T11:17:40.082700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 32 permutations minhash LSH with >= 0.5 threshold\n",
    "minhash_objects_32 = []\n",
    "\n",
    "def create_minhash(tokens):\n",
    "    minhash = MinHash(num_perm=32)\n",
    "    for token in tokens:\n",
    "        minhash.update(token.encode('utf8'))\n",
    "    return minhash\n",
    "\n",
    "start_time = time.time()\n",
    "minhash_objects_32 = list(map(create_minhash, train_df['Tokenized']))\n",
    "\n",
    "# Create MinHashLSH Index\n",
    "lsh2 = MinHashLSH(threshold=0.5, num_perm=32)\n",
    "\n",
    "for i, minhash in enumerate(minhash_objects_32):\n",
    "    lsh2.insert(i, minhash)\n",
    "\n",
    "build_time = time.time() - start_time\n",
    "print(f\"Build time (lsh with 32 permutations, threshold >= 0.5): {build_time} seconds\")\n",
    "\n",
    "# Create MinHash objects for test_df\n",
    "start_time = time.time()\n",
    "test_minhash_objects_32 = list(map(create_minhash, test_df['Tokenized']))\n",
    "\n",
    "# Query MinHashLSH for candidates in train_df\n",
    "    \n",
    "test_candidates_32 = [lsh2.query(minhash) for minhash in test_minhash_objects_32]    \n",
    "\n",
    "query_time = time.time() - start_time\n",
    "print(f\"Query time (lsh with 32 permutations, threshold >= 0.5): {query_time} seconds\")\n",
    "\n",
    "# print(test_candidates)\n",
    "print('min hash done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T11:23:08.868893Z",
     "iopub.status.busy": "2024-01-11T11:23:08.867871Z",
     "iopub.status.idle": "2024-01-11T11:23:08.987477Z",
     "shell.execute_reply": "2024-01-11T11:23:08.986294Z",
     "shell.execute_reply.started": "2024-01-11T11:23:08.868862Z"
    }
   },
   "outputs": [],
   "source": [
    "# , jic -> / 100\n",
    "test_candidates_flat_32 = [item for sublist in test_candidates_32 for item in sublist]\n",
    "print(len(test_candidates_flat_32))\n",
    "indices_flat = indices.flatten()\n",
    "print(\"Fraction of true k-most similar docs found by LSH (32 perms, >= 0.5 threshold): \", len(set(test_candidates_flat_32).intersection(indices_flat)) / 15) # find fraction for K=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T11:23:39.883549Z",
     "iopub.status.busy": "2024-01-11T11:23:39.883217Z",
     "iopub.status.idle": "2024-01-11T11:29:39.308054Z",
     "shell.execute_reply": "2024-01-11T11:29:39.306617Z",
     "shell.execute_reply.started": "2024-01-11T11:23:39.883527Z"
    }
   },
   "outputs": [],
   "source": [
    "# 64 permutations minhash LSH with >= 0.5 threshold\n",
    "minhash_objects_64 = []\n",
    "\n",
    "def create_minhash(tokens):\n",
    "    minhash = MinHash(num_perm=64)\n",
    "    for token in tokens:\n",
    "        minhash.update(token.encode('utf8'))\n",
    "    return minhash\n",
    "\n",
    "start_time = time.time()\n",
    "minhash_objects_64 = list(map(create_minhash, train_df['Tokenized']))\n",
    "\n",
    "# Create MinHashLSH Index\n",
    "lsh3 = MinHashLSH(threshold=0.5, num_perm=64)\n",
    "\n",
    "for i, minhash in enumerate(minhash_objects_64):\n",
    "    lsh3.insert(i, minhash)\n",
    "\n",
    "build_time = time.time() - start_time\n",
    "print(f\"Build time (lsh with 64 permutations, threshold >= 0.5): {build_time} seconds\")\n",
    "\n",
    "# Create MinHash objects for test_df\n",
    "start_time = time.time()\n",
    "test_minhash_objects_64 = list(map(create_minhash, test_df['Tokenized']))\n",
    "\n",
    "# Query MinHashLSH for candidates in train_df\n",
    "    \n",
    "test_candidates_64 = [lsh3.query(minhash) for minhash in test_minhash_objects_64]    \n",
    "\n",
    "query_time = time.time() - start_time\n",
    "print(f\"Query time (lsh with 64 permutations, threshold >= 0.5): {query_time} seconds\")\n",
    "\n",
    "# print(test_candidates)\n",
    "print('min hash done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T11:29:42.841454Z",
     "iopub.status.busy": "2024-01-11T11:29:42.840409Z",
     "iopub.status.idle": "2024-01-11T11:29:43.014689Z",
     "shell.execute_reply": "2024-01-11T11:29:43.013704Z",
     "shell.execute_reply.started": "2024-01-11T11:29:42.841416Z"
    }
   },
   "outputs": [],
   "source": [
    "# jic -> / 100\n",
    "test_candidates_flat_64 = [item for sublist in test_candidates_64 for item in sublist]\n",
    "print(len(test_candidates_flat_64))\n",
    "indices_flat = indices.flatten()\n",
    "print(\"Fraction of true k-most similar docs found by LSH (64 perms, >= 0.5 threshold): \", len(set(test_candidates_flat_64).intersection(indices_flat)) / 15) # find fraction for K=15"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7177791,
     "sourceId": 65242,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
